{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\river\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\river\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\river\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "c:\\Users\\river\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import types\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "# from gensim.parsing.porter import PorterStemmer\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import words\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "# from gensim.models import Word2Vec\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# import en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "word = \"hospital\"\n",
    "lower_upper_alphabet = string.ascii_letters\n",
    "\n",
    "for _ in range(1):\n",
    "  random_letter = random.choice(lower_upper_alphabet)\n",
    "  i = random.randint(1,len(word))\n",
    "  word = word[:i] + random_letter.lower() + word[i:]\n",
    "books=[]\n",
    "urls=[]\n",
    "\n",
    "urls.append(\"https://www.gutenberg.org/files/51660/51660-0.txt\")\n",
    "# urls.append(\"https://www.gutenberg.org/files/20023/20023-8.txt\")\n",
    "# urls.append(\"https://www.gutenberg.org/files/36641/36641-8.txt\")\n",
    "# urls.append(\"https://www.gutenberg.org/files/63444/63444-0.txt\")\n",
    "# urls.append(\"https://www.gutenberg.org/files/1265/1265.txt\")\n",
    "\n",
    "for url in urls:\n",
    "  books.append(requests.get(url).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def apply_error(word, remove=0.3, add=0.3, swap_letter=True):\n",
    "  def swap(s, i, j):\n",
    "    return ''.join((s[:i], s[j], s[i+1:j], s[i], s[j+1:]))\n",
    "\n",
    "  if swap_letter:\n",
    "    i = random.randint(0,len(word)-1)\n",
    "    j = random.randint(0,len(word)-1)\n",
    "    word = swap(word, i, j)\n",
    "\n",
    "  letters_to_remove = int(remove*len(word))\n",
    "  letters_to_add = int(add*len(word))\n",
    "\n",
    "  for _ in range(letters_to_remove):\n",
    "    i = random.randint(1,len(word))\n",
    "    word = word[:i-1] + word[i:]\n",
    "\n",
    "  lower_upper_alphabet = string.ascii_letters\n",
    "  for _ in range(letters_to_add):\n",
    "    random_letter = random.choice(lower_upper_alphabet)\n",
    "    i = random.randint(1,len(word))\n",
    "    word = word[:i] + random_letter.lower() + word[i:]\n",
    "\n",
    "  return word\n",
    "\n",
    "def prepare_data(text):\n",
    "  # to lower case\n",
    "  text = text.lower()\n",
    "  \n",
    "  # Remove non-ascii characters\n",
    "  text = text.encode(\"ascii\", \"ignore\").decode()\n",
    "\n",
    "  # Remove \\n and \\r\n",
    "  text = re.sub(r'[\\r*\\n*]+', ' ', text)\n",
    "\n",
    "  # Remove websites and hashtags\n",
    "  text = re.sub(r'_|#|http\\S+|www\\S+', ' ', text)\n",
    "\n",
    "  # Substitute numbers by keyword num\n",
    "  text = re.sub(r'\\d+', 'num', text)\n",
    "\n",
    "  \n",
    "  # Divide into sentences\n",
    "  # sents = text_to_sent_list(text, nlp)\n",
    "\n",
    "  # Apply tokenization\n",
    "  regex = r\"\\w+'?\\w+\\s\"\n",
    "  words = re.findall(regex,text)\n",
    "  words = [w[:-1] for w in words]\n",
    "  words = [w for w in words if len(w)>1 or w in [\"a\", \"i\"]]\n",
    "\n",
    "  unique = np.unique(words, return_counts=True)\n",
    "  [[w, c] for w, c in zip(*unique) if  len(w) == 2]\n",
    "\n",
    "  return words\n",
    "\n",
    "words = [prepare_data(book) for book in books]\n",
    "words = [y for x in words for y in x]\n",
    "\n",
    "\n",
    "words = set(words)\n",
    "\n",
    "# multiplication_factor = 3\n",
    "# for i in range(3):\n",
    "#   words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_words = list(set(prepare_data(books[0])))\n",
    "my_wrong1 =[]\n",
    "my_wrong2 =[]\n",
    "my_wrong3 =[]\n",
    "my_wrong4 =[]\n",
    "my_wrong5 =[]\n",
    "for correct in correct_words:\n",
    "  \n",
    "  my_wrong1.append(apply_error(correct, remove=0.1, add=0.1,swap_letter=True))\n",
    "  my_wrong2.append(apply_error(correct, remove=0.1, add=0.1, swap_letter=True))\n",
    "  my_wrong3.append(apply_error(correct, remove=0.2, add=0.1))\n",
    "  my_wrong4.append(apply_error(correct, remove=0.2, add=0.1,swap_letter=True))\n",
    "  my_wrong5.append(apply_error(correct, remove=0.1, add=0.2,swap_letter=True))\n",
    "  # print(correct,my_wrong)\n",
    "  # wrong_data.append(my_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>wrong1</th>\n",
       "      <th>wrong2</th>\n",
       "      <th>wrong3</th>\n",
       "      <th>wrong4</th>\n",
       "      <th>wrong5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unimagined</td>\n",
       "      <td>unuinimzained</td>\n",
       "      <td>unimamgagineb</td>\n",
       "      <td>nnimainedn</td>\n",
       "      <td>unimainleed</td>\n",
       "      <td>gnimmauiegd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forests</td>\n",
       "      <td>faorestests</td>\n",
       "      <td>foserts</td>\n",
       "      <td>orrests</td>\n",
       "      <td>sorefs</td>\n",
       "      <td>forestprsetso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fainted</td>\n",
       "      <td>ftinaed</td>\n",
       "      <td>faintientdd</td>\n",
       "      <td>naifed</td>\n",
       "      <td>fniate</td>\n",
       "      <td>faintder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>numerous</td>\n",
       "      <td>numersuo</td>\n",
       "      <td>numerwoeuous</td>\n",
       "      <td>nuhmerrou</td>\n",
       "      <td>ntmeruomrous</td>\n",
       "      <td>umieerrousr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tallest</td>\n",
       "      <td>tllaelsest</td>\n",
       "      <td>tallllest</td>\n",
       "      <td>telast</td>\n",
       "      <td>alelesttalest</td>\n",
       "      <td>tatlejsl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>therefor</td>\n",
       "      <td>ehertfor</td>\n",
       "      <td>thfreeor</td>\n",
       "      <td>tthrefor</td>\n",
       "      <td>terefor</td>\n",
       "      <td>teerihfor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>doves</td>\n",
       "      <td>dooves</td>\n",
       "      <td>dovess</td>\n",
       "      <td>ovvees</td>\n",
       "      <td>dvse</td>\n",
       "      <td>sovedr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>bedecked</td>\n",
       "      <td>beddckee</td>\n",
       "      <td>beecekczked</td>\n",
       "      <td>beedeked</td>\n",
       "      <td>edeckbdeckezd</td>\n",
       "      <td>bedreckedd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>revelry</td>\n",
       "      <td>rreevelry</td>\n",
       "      <td>remvelreyelry</td>\n",
       "      <td>revely</td>\n",
       "      <td>reveorleery</td>\n",
       "      <td>revfeellry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10980</th>\n",
       "      <td>ye</td>\n",
       "      <td>ey</td>\n",
       "      <td>yee</td>\n",
       "      <td>yyee</td>\n",
       "      <td>yyee</td>\n",
       "      <td>yee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10981 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          correct         wrong1         wrong2      wrong3         wrong4  \\\n",
       "0      unimagined  unuinimzained  unimamgagineb  nnimainedn    unimainleed   \n",
       "1         forests    faorestests        foserts     orrests         sorefs   \n",
       "2         fainted        ftinaed    faintientdd      naifed         fniate   \n",
       "3        numerous       numersuo   numerwoeuous   nuhmerrou   ntmeruomrous   \n",
       "4         tallest     tllaelsest      tallllest      telast  alelesttalest   \n",
       "...           ...            ...            ...         ...            ...   \n",
       "10976    therefor       ehertfor       thfreeor    tthrefor        terefor   \n",
       "10977       doves         dooves         dovess      ovvees           dvse   \n",
       "10978    bedecked       beddckee    beecekczked    beedeked  edeckbdeckezd   \n",
       "10979     revelry      rreevelry  remvelreyelry      revely    reveorleery   \n",
       "10980          ye             ey            yee        yyee           yyee   \n",
       "\n",
       "              wrong5  \n",
       "0        gnimmauiegd  \n",
       "1      forestprsetso  \n",
       "2           faintder  \n",
       "3        umieerrousr  \n",
       "4           tatlejsl  \n",
       "...              ...  \n",
       "10976      teerihfor  \n",
       "10977         sovedr  \n",
       "10978     bedreckedd  \n",
       "10979     revfeellry  \n",
       "10980            yee  \n",
       "\n",
       "[10981 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"correct\":correct_words,\"wrong1\":my_wrong1,\"wrong2\":my_wrong2,\"wrong3\":my_wrong3,\"wrong4\":my_wrong4,\"wrong5\":my_wrong5})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myWord2vec(word):\n",
    "    vector  = [0]*26    \n",
    "    for c in word:\n",
    "        index = ord(c)-97\n",
    "        if index>=26 or index <0:\n",
    "            continue\n",
    "        vector[index]+=1\n",
    "    return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myWord2vec(\"your're\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myWord2vec(\"aaahmed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myWord2vec(\"ahamed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " [0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      "B:\n",
      " [1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "Cosine Similarity:\n",
      " 0.6123724356957946\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    " \n",
    "# define two lists or array\n",
    "A = np.array(myWord2vec(\"sendom\"))\n",
    "B = np.array(myWord2vec(\"sand\"))\n",
    "print(\"A:\\n\", A)\n",
    "print(\"B:\\n\", B)\n",
    " \n",
    "# compute cosine similarity\n",
    "cosine = np.dot(A,B)/(norm(A, axis=0)*norm(B))\n",
    "print(\"Cosine Similarity:\\n\", cosine)\n",
    "\n",
    "dist = np.linalg.norm(A - B)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosin_similarity(word1,word2):\n",
    "    # print(word1,word2)\n",
    "    A = np.array(myWord2vec(word1))\n",
    "    B = np.array(myWord2vec(word2))\n",
    "\n",
    "    # compute cosine similarity\n",
    "    cosine = np.dot(A,B)/(norm(A, axis=0)*norm(B))\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_similar(word, posibilites):\n",
    "    matched_word  = \"\"\n",
    "    max_s = 0\n",
    "    for w in posibilites:\n",
    "        cos = cosin_similarity(word,w)\n",
    "        if cos>max_s:\n",
    "            max_s = cos\n",
    "            matched_word = w\n",
    "    return matched_word,max_s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10981\n"
     ]
    }
   ],
   "source": [
    "from numpy.ma.core import empty\n",
    "max = len(df)\n",
    "print(max)\n",
    "correct_words =correct_words[:max] \n",
    "wrong1_performance =[]\n",
    "num_correct = 0\n",
    "for i in range(max):\n",
    "  correct_w = df.iloc[i,0]\n",
    "  wrong = df.iloc[i,1]\n",
    "  flag = 0\n",
    "  close_matches, cos_value = get_most_similar(wrong, correct_words)\n",
    "  \n",
    "  # print(close_matches, cos_value)\n",
    "  if close_matches is not empty and close_matches == correct_w:\n",
    "    num_correct+=1\n",
    "    flag = 1\n",
    "  wrong1_performance.append((flag, close_matches, cos_value))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9280"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10981"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wrong1_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['wrong1_performance'] = wrong1_performance\n",
    "df = df[['correct', 'wrong1', 'wrong1_performance', \"wrong2\",'wrong3',\"wrong4\",\"wrong5\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9280\n",
      "accuracy:  0.8450960750387032\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>wrong1</th>\n",
       "      <th>wrong1_performance</th>\n",
       "      <th>wrong2</th>\n",
       "      <th>wrong3</th>\n",
       "      <th>wrong4</th>\n",
       "      <th>wrong5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unimagined</td>\n",
       "      <td>unuinimzained</td>\n",
       "      <td>(1, unimagined, 0.9258200997725514)</td>\n",
       "      <td>unimamgagineb</td>\n",
       "      <td>nnimainedn</td>\n",
       "      <td>unimainleed</td>\n",
       "      <td>gnimmauiegd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forests</td>\n",
       "      <td>faorestests</td>\n",
       "      <td>(1, forests, 0.9456108576893003)</td>\n",
       "      <td>foserts</td>\n",
       "      <td>orrests</td>\n",
       "      <td>sorefs</td>\n",
       "      <td>forestprsetso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fainted</td>\n",
       "      <td>ftinaed</td>\n",
       "      <td>(1, fainted, 0.9999999999999999)</td>\n",
       "      <td>faintientdd</td>\n",
       "      <td>naifed</td>\n",
       "      <td>fniate</td>\n",
       "      <td>faintder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>numerous</td>\n",
       "      <td>numersuo</td>\n",
       "      <td>(1, numerous, 0.9999999999999998)</td>\n",
       "      <td>numerwoeuous</td>\n",
       "      <td>nuhmerrou</td>\n",
       "      <td>ntmeruomrous</td>\n",
       "      <td>umieerrousr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tallest</td>\n",
       "      <td>tllaelsest</td>\n",
       "      <td>(0, tells, 0.9669875568304563)</td>\n",
       "      <td>tallllest</td>\n",
       "      <td>telast</td>\n",
       "      <td>alelesttalest</td>\n",
       "      <td>tatlejsl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>therefor</td>\n",
       "      <td>ehertfor</td>\n",
       "      <td>(1, therefor, 1.0000000000000002)</td>\n",
       "      <td>thfreeor</td>\n",
       "      <td>tthrefor</td>\n",
       "      <td>terefor</td>\n",
       "      <td>teerihfor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>doves</td>\n",
       "      <td>dooves</td>\n",
       "      <td>(1, doves, 0.9486832980505138)</td>\n",
       "      <td>dovess</td>\n",
       "      <td>ovvees</td>\n",
       "      <td>dvse</td>\n",
       "      <td>sovedr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>bedecked</td>\n",
       "      <td>beddckee</td>\n",
       "      <td>(1, bedecked, 1.0)</td>\n",
       "      <td>beecekczked</td>\n",
       "      <td>beedeked</td>\n",
       "      <td>edeckbdeckezd</td>\n",
       "      <td>bedreckedd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>revelry</td>\n",
       "      <td>rreevelry</td>\n",
       "      <td>(1, revelry, 0.9869275424396536)</td>\n",
       "      <td>remvelreyelry</td>\n",
       "      <td>revely</td>\n",
       "      <td>reveorleery</td>\n",
       "      <td>revfeellry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10980</th>\n",
       "      <td>ye</td>\n",
       "      <td>ey</td>\n",
       "      <td>(1, ye, 0.9999999999999998)</td>\n",
       "      <td>yee</td>\n",
       "      <td>yyee</td>\n",
       "      <td>yyee</td>\n",
       "      <td>yee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10981 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          correct         wrong1                   wrong1_performance  \\\n",
       "0      unimagined  unuinimzained  (1, unimagined, 0.9258200997725514)   \n",
       "1         forests    faorestests     (1, forests, 0.9456108576893003)   \n",
       "2         fainted        ftinaed     (1, fainted, 0.9999999999999999)   \n",
       "3        numerous       numersuo    (1, numerous, 0.9999999999999998)   \n",
       "4         tallest     tllaelsest       (0, tells, 0.9669875568304563)   \n",
       "...           ...            ...                                  ...   \n",
       "10976    therefor       ehertfor    (1, therefor, 1.0000000000000002)   \n",
       "10977       doves         dooves       (1, doves, 0.9486832980505138)   \n",
       "10978    bedecked       beddckee                   (1, bedecked, 1.0)   \n",
       "10979     revelry      rreevelry     (1, revelry, 0.9869275424396536)   \n",
       "10980          ye             ey          (1, ye, 0.9999999999999998)   \n",
       "\n",
       "              wrong2      wrong3         wrong4         wrong5  \n",
       "0      unimamgagineb  nnimainedn    unimainleed    gnimmauiegd  \n",
       "1            foserts     orrests         sorefs  forestprsetso  \n",
       "2        faintientdd      naifed         fniate       faintder  \n",
       "3       numerwoeuous   nuhmerrou   ntmeruomrous    umieerrousr  \n",
       "4          tallllest      telast  alelesttalest       tatlejsl  \n",
       "...              ...         ...            ...            ...  \n",
       "10976       thfreeor    tthrefor        terefor      teerihfor  \n",
       "10977         dovess      ovvees           dvse         sovedr  \n",
       "10978    beecekczked    beedeked  edeckbdeckezd     bedreckedd  \n",
       "10979  remvelreyelry      revely    reveorleery     revfeellry  \n",
       "10980            yee        yyee           yyee            yee  \n",
       "\n",
       "[10981 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(num_correct)\n",
    "print(\"accuracy: \",num_correct/max)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "a = (1, 2, 3)\n",
    "b = (4, 5, 6)\n",
    "dst = distance.euclidean(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.euclidean(myWord2vec(\"ahmed\"),myWord2vec(\"hamed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosin_similarity(\"ahmed\",\"hamed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosin_similarity(\"revolst\",\"revolts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('abundance', 0.9013878188659974)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_similar(\"abunddanjc\",correct_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61988e2b4f5b0ccee1d845266b40130c59f7d62973977e0b1b53b9b8b4cf0fa0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
